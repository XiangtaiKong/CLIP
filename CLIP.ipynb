{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CLIP.ipynb","provenance":[],"authorship_tag":"ABX9TyMd7erZnzyscdXDwN7Siht5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kUEGe-SEC2jf","executionInfo":{"status":"ok","timestamp":1645258599328,"user_tz":-480,"elapsed":12080,"user":{"displayName":"wei zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04847911625399866224"}},"outputId":"fbfde479-4caf-4afe-d2a7-966d5c70d1c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[?25l\r\u001b[K     |██████▏                         | 10 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 53 kB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n","Installing collected packages: ftfy\n","Successfully installed ftfy-6.1.1\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-m5y55rn7\n","  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-m5y55rn7\n","Collecting install\n","  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.62.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.10.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.11.1+cu111)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.10.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.5)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369221 sha256=c48ae56ff7d4fccd0ef42ec101899b481de967b96b362009680ce51ebb971290\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-iy4ifp73/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n","Successfully built clip\n","Installing collected packages: install, clip\n","Successfully installed clip-1.0 install-1.3.5\n"]}],"source":["!pip install ftfy regex tqdm\n","!pip install install git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import clip\n","from PIL import Image\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hv2RTRMvDZKQ","executionInfo":{"status":"ok","timestamp":1645258753176,"user_tz":-480,"elapsed":13078,"user":{"displayName":"wei zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04847911625399866224"}},"outputId":"c872b76c-93e4-420e-b1ad-866d2403073f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 177MiB/s]\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PodxMwUfFrVZ","executionInfo":{"status":"ok","timestamp":1645259178222,"user_tz":-480,"elapsed":567,"user":{"displayName":"wei zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04847911625399866224"}},"outputId":"4e9b9827-a9db-4a7b-cf23-8961a0272799"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\n"]}]},{"cell_type":"code","source":["image = preprocess(Image.open(\"hongbao.png\")).unsqueeze(0).to(device)\n","text = clip.tokenize([\"money\",\"notebook\",\"red bag\",\"red\",\"China\",\"facai\"]).to(device)\n","\n","with torch.no_grad():\n","  image_features = model.encode_image(image)\n","  text_features = model.encode_text(text)\n","\n","  logits_per_image, logits_per_text = model(image, text)\n","  probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","\n","print(\"Label probes:\", probs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_8WsFaQDHGo","executionInfo":{"status":"ok","timestamp":1645259662682,"user_tz":-480,"elapsed":2275,"user":{"displayName":"wei zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04847911625399866224"}},"outputId":"49357a47-dd87-4639-bd40-8078f0787b3d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Label probes: [[0.00561551 0.00288907 0.16840048 0.0395425  0.7818444  0.00170803]]\n"]}]}]}